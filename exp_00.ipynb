{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Model, Input to BERT Layer is Embedded (Not Tokens Ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFBertForMaskedLM\n",
    "from transformers import TFCamembertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters\n",
    "\n",
    "vocabSize = 32005\n",
    "batchSize = 1\n",
    "sequenceSize = 32\n",
    "hiddenDimension = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=int32, numpy=\n",
       "array([[  109,    48,  3685,    36,   766,    18,    11,    59,  2615,\n",
       "         3633,    52, 12279, 19464,    68,  7498, 24377,    10,    14,\n",
       "           36,  3287, 22208,   141,   109,    48,  3685,    36,   766,\n",
       "           18,    11,    59,  2615,  3633]], dtype=int32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Generate a Tensor of tokens_ids\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jplu/tf-camembert-base\", do_lower_case=True)\n",
    "sentence = \"Elle se situe au cœur d'un vaste bassin sédimentaire aux sols fertiles et au climat tempéré Elle se situe au cœur d'un vaste bassin\"\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "tensor = tf.convert_to_tensor(tokens_ids)\n",
    "tensor = tf.expand_dims(tensor, 0)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Check BERT output\n",
    "\n",
    "# bertLayer = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")\n",
    "# bertLayer(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### generate a random tensor\n",
    "# randTensor = tf.random.uniform(shape=[batchSize, sequenceSize, hiddenDimension])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Check BERT output\n",
    "\n",
    "# bertLayer(None, inputs_embeds=randTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = tf.keras.Input(shape=(32), dtype='int32')\n",
    "# x = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")(inp)[0]\n",
    "# x = tf.keras.layers.Reshape((sequenceSize*vocabSize,))(x)\n",
    "# out = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "# model = tf.keras.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = tf.keras.Input(shape=(sequenceSize, hiddenDimension), batch_size=batchSize, dtype='float32')\n",
    "# x = bertLayer(None, inputs_embeds=inp)[0]\n",
    "# x = tf.keras.layers.Reshape((sequenceSize*vocabSize,))(x)\n",
    "# out = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "# model = tf.keras.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(randTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Model With a Linear Projection at the Beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tf.zeros(shape=[batchSize, sequenceSize, vocabSize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32, 768), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Build a Linear Layer to Embed the tokens_ids\n",
    "\n",
    "linearProj = tf.keras.layers.Dense(768, input_shape=(vocabSize,), use_bias=False)\n",
    "linearProj(tensor)  # execute the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate a random tensor\n",
    "randTensor = tf.random.uniform(shape=[batchSize, sequenceSize, hiddenDimension])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 32, 32005), dtype=float32, numpy=\n",
       " array([[[18.29583   , -4.882077  ,  6.7804275 , ..., -6.1650743 ,\n",
       "          -3.6798992 ,  0.74201536],\n",
       "         [-2.2358382 , -4.3069005 ,  9.268164  , ..., -5.5183606 ,\n",
       "          -3.5315247 , -4.1858497 ],\n",
       "         [-2.215941  , -4.8831463 ,  3.6801977 , ..., -6.437811  ,\n",
       "          -4.0220213 , -3.5282693 ],\n",
       "         ...,\n",
       "         [-2.3257854 , -4.4981136 ,  9.450423  , ..., -4.9840775 ,\n",
       "          -4.489959  , -3.028567  ],\n",
       "         [-2.9122112 , -5.208738  ,  5.2395935 , ..., -4.728059  ,\n",
       "          -3.7446043 , -2.3865955 ],\n",
       "         [-0.60326767, -3.964406  , 13.500547  , ..., -5.69354   ,\n",
       "          -3.5518374 , -2.7256484 ]]], dtype=float32)>,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertLayer = TFCamembertForMaskedLM.from_pretrained(\"jplu/tf-camembert-base\")\n",
    "bertLayer(None, inputs_embeds=randTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build the Experimental Model\n",
    "\n",
    "inp = tf.keras.Input(shape=(sequenceSize, vocabSize), batch_size=batchSize, dtype='float32')\n",
    "x = linearProj(inp)\n",
    "x = bertLayer(None, inputs_embeds=x)[0]\n",
    "x = tf.keras.layers.Reshape((sequenceSize*vocabSize,))(x)\n",
    "out = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "modelExp = tf.keras.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[3.5208745e-05, 9.9996483e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelExp(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to Build The Input for the Experimental Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32, 32005), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### build the input one-hot encoding the sentence\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "tensor = tf.convert_to_tensor(tokens_ids)\n",
    "tensor = tf.expand_dims(tf.one_hot(tensor, vocabSize), 0)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[9.821886e-06, 9.999902e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### run the model on the input\n",
    "modelExp(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvTrans",
   "language": "python",
   "name": "venvtrans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
