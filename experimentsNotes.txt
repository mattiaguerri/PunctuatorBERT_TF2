

==============================================================================================

"Models/20200425_142515/cp-008.ckpt"
Trained on the extract of IWSLT12.
Trained the full model.
Epoch 008, Loss 0.040, Acc 99.896.
Inferring on extractInfer, model is able to produce space comma period question.

Evaluated on extractTrain:
Rec_0: 0.9941 - Prec_0: 0.9974 - Rec_1: 0.7928 - Prec_1: 0.9659 - Rec_2: 0.9866 - Prec_2: 0.8258 - Rec_3: 1.0000 - Prec_3: 0.8148

Evaluated on extractTest:
Rec_0: 0.9750 - Prec_0: 0.9793 - Rec_1: 0.3603 - Prec_1: 0.6806 - Rec_2: 0.8818 - Prec_2: 0.6065 - Rec_3: 0.6207 - Prec_3: 0.3913

==============================================================================================


==============================================================================================

"Models/20200430_100559/cp-006.ckpt"
Trained only TOP PART of the model.
Trained on the full IWSLT12.

Epoch 001: (Training)   Loss: 27.371, Accuracy: 88.609%
Epoch 002: (Training)   Loss: 23.732, Accuracy: 90.506%
Epoch 003: (Training)   Loss: 23.307, Accuracy: 90.987%
Epoch 004: (Training)   Loss: 23.181, Accuracy: 91.253%
Epoch 005: (Training)   Loss: 22.824, Accuracy: 91.445%
Epoch 006: (Training)   Loss: 22.712, Accuracy: 91.585%
Epoch 007: (Training)   Loss: 22.981, Accuracy: 91.684%
Epoch 008: (Training)   Loss: 22.636, Accuracy: 91.769%
Epoch 009: (Training)   Loss: 23.494, Accuracy: 91.783%
Epoch 010: (Training)   Loss: 23.019, Accuracy: 91.883%
Evaluation on IWSLT12.TALK.train.en.txt.Test_01
Rec_0: 0.9889 - Prec_0: 0.9536 - Rec_1: 0.4576 - Prec_1: 0.5945 - Rec_2: 0.6017 - Prec_2: 0.8039 - Rec_3: 0.1584 - Prec_3: 0.9275

Same shit but buffer size = 1000000
Epoch 001: (Training)   Loss: 17.543, Accuracy: 89.410%
Epoch 002: (Training)   Loss: 17.494, Accuracy: 90.636%
Epoch 003: (Training)   Loss: 17.705, Accuracy: 90.878%
Epoch 004: (Training)   Loss: 17.620, Accuracy: 91.088%
Epoch 005: (Training)   Loss: 17.631, Accuracy: 91.216%
Epoch 006: (Training)   Loss: 17.946, Accuracy: 91.265%

Same shit but learning rate = 1e-5, buffer size = 500000
Epoch 001: (Training)   Loss: 1.196, Accuracy: 89.475%
Epoch 002: (Training)   Loss: 1.104, Accuracy: 90.625%
Epoch 003: (Training)   Loss: 1.109, Accuracy: 90.929%
Epoch 004: (Training)   Loss: 1.097, Accuracy: 91.096%
Epoch 005: (Training)   Loss: 1.088, Accuracy: 91.218%
Epoch 006: (Training)   Loss: 1.108, Accuracy: 91.267%

==============================================================================================






==============================================================================================

Models/20200508_085150/
Trained the FULL MODEL.
Trained on the full IWSLT12.

vocab_size = 30522
segment_size = 16
batch_size = 128
train_layer_ind = 0
learat = 1e-5

Epoch 001: (Training)   Loss: 0.147, Accuracy: 95.016%
Epoch 002: (Training)   Loss: 0.099, Accuracy: 96.542%
Epoch 003: (Training)   Loss: 0.063, Accuracy: 98.085%
Epoch 004: (Training)   Loss: 0.032, Accuracy: 99.313%
Epoch 005: (Training)   Loss: 0.016, Accuracy: 99.847%
Epoch 006: (Training)   Loss: 0.010, Accuracy: 99.964%
Epoch 007: (Training)   Loss: 0.008, Accuracy: 99.986%
Epoch 008: (Training)   Loss: 0.007, Accuracy: 99.991%
Epoch 009: (Training)   Loss: 0.007, Accuracy: 99.995%
Epoch 010: (Training)   Loss: 0.006, Accuracy: 99.995%

Evaluated on the full test set.
loss: 0.3659 - Rec_0: 0.9840 - Prec_0: 0.9799 - Rec_1: 0.6396 - Prec_1: 0.6330 - Rec_2: 0.7388 - Prec_2: 0.7918 - Rec_3: 0.4827 - Prec_3: 0.6190

==============================================================================================






==============================================================================================

20200510_101117

Trained the FULL MODEL.
Trained on the FULL SCRIBER.
In this model the output is a vector in R4, instead of a vector in R2, as it should have been!!!

Epoch 001: (Training)   Loss: 0.126, Accuracy: 95.233%
Epoch 002: (Training)   Loss: 0.094, Accuracy: 95.938%
Epoch 003: (Training)   Loss: 0.074, Accuracy: 97.018%
Epoch 004: (Training)   Loss: 0.050, Accuracy: 98.411%
Epoch 005: (Training)   Loss: 0.030, Accuracy: 99.360%
Epoch 006: (Training)   Loss: 0.019, Accuracy: 99.770%
Epoch 007: (Training)   Loss: 0.014, Accuracy: 99.898%
Epoch 008: (Training)   Loss: 0.012, Accuracy: 99.932%
Epoch 009: (Training)   Loss: 0.010, Accuracy: 99.953%
Epoch 010: (Training)   Loss: 0.009, Accuracy: 99.962%


ModelsExpScriber/20200510_101117/cp-001.ckpt
657/657 [==============================] - 42s 63ms/step - loss: 0.1132 - Rec_0: 0.9834 - Prec_0: 0.9609 - Rec_1: 0.4909 - Prec_1: 0.6989
ModelsExpScriber/20200510_101117/cp-002.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.1198 - Rec_0: 0.9875 - Prec_0: 0.9577 - Rec_1: 0.4458 - Prec_1: 0.7368
ModelsExpScriber/20200510_101117/cp-003.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.1390 - Rec_0: 0.9786 - Prec_0: 0.9606 - Rec_1: 0.4896 - Prec_1: 0.6427
ModelsExpScriber/20200510_101117/cp-004.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.1861 - Rec_0: 0.9838 - Prec_0: 0.9535 - Rec_1: 0.3903 - Prec_1: 0.6550
ModelsExpScriber/20200510_101117/cp-005.ckpt
657/657 [==============================] - 40s 62ms/step - loss: 0.2349 - Rec_0: 0.9792 - Prec_0: 0.9597 - Rec_1: 0.4778 - Prec_1: 0.6432
ModelsExpScriber/20200510_101117/cp-006.ckpt
657/657 [==============================] - 41s 62ms/step - loss: 0.2477 - Rec_0: 0.9779 - Prec_0: 0.9584 - Rec_1: 0.4608 - Prec_1: 0.6215
ModelsExpScriber/20200510_101117/cp-007.ckpt
657/657 [==============================] - 40s 62ms/step - loss: 0.2914 - Rec_0: 0.9766 - Prec_0: 0.9591 - Rec_1: 0.4700 - Prec_1: 0.6128
ModelsExpScriber/20200510_101117/cp-008.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.3474 - Rec_0: 0.9797 - Prec_0: 0.9587 - Rec_1: 0.4634 - Prec_1: 0.6420
ModelsExpScriber/20200510_101117/cp-009.ckpt
657/657 [==============================] - 41s 62ms/step - loss: 0.3053 - Rec_0: 0.9741 - Prec_0: 0.9613 - Rec_1: 0.5013 - Prec_1: 0.6038
ModelsExpScriber/20200510_101117/cp-010.ckpt
657/657 [==============================] - 40s 62ms/step - loss: 0.3243 - Rec_0: 0.9651 - Prec_0: 0.9676 - Rec_1: 0.5888 - Prec_1: 0.5705, F1 = 0.5795

==============================================================================================






==============================================================================================
----------------------------------------------------------------------------------------------

20200512_083058

Trained the FULL MODEL.
Trained on the FULL SCRIBER.
In this model the output is a vector in R2.

vocab_size = 32005
segment_size = 32
batch_size = 64
train_layer_ind = 0
learat = 1e-5
num_epochs = 10

TRAINING
Epoch 001: (Training)   Loss: 0.124, Accuracy: 95.279%
Epoch 002: (Training)   Loss: 0.093, Accuracy: 95.996%
Epoch 003: (Training)   Loss: 0.072, Accuracy: 97.137%
Epoch 004: (Training)   Loss: 0.047, Accuracy: 98.580%
Epoch 005: (Training)   Loss: 0.027, Accuracy: 99.504%
Epoch 006: (Training)   Loss: 0.017, Accuracy: 99.839%
Epoch 007: (Training)   Loss: 0.013, Accuracy: 99.923%
Epoch 008: (Training)   Loss: 0.011, Accuracy: 99.948%
Epoch 009: (Training)   Loss: 0.010, Accuracy: 99.962%
Epoch 010: (Training)   Loss: 0.009, Accuracy: 99.967%

EVALUATION
ModelsExpScriber/20200512_083058/cp-001.ckpt
657/657 [==============================] - 51s 77ms/step - loss: 0.1134 - Rec_0: 0.9819 - Prec_0: 0.9648 - Rec_1: 0.5444 - Prec_1: 0.7026
F1_0 =  0.9732563002953498    F1_1 =  0.613460843177117
ModelsExpScriber/20200512_083058/cp-002.ckpt
657/657 [==============================] - 38s 58ms/step - loss: 0.1240 - Rec_0: 0.9917 - Prec_0: 0.9494 - Rec_1: 0.3277 - Prec_1: 0.7572
F1_0 =  0.9700926868956044    F1_1 =  0.4574031765755492
ModelsExpScriber/20200512_083058/cp-003.ckpt
657/657 [==============================] - 39s 59ms/step - loss: 0.1489 - Rec_0: 0.9894 - Prec_0: 0.9510 - Rec_1: 0.3518 - Prec_1: 0.7225
F1_0 =  0.969803723959994    F1_1 =  0.4732221539450275
ModelsExpScriber/20200512_083058/cp-004.ckpt
657/657 [==============================] - 39s 60ms/step - loss: 0.1768 - Rec_0: 0.9652 - Prec_0: 0.9702 - Rec_1: 0.6227 - Prec_1: 0.5849
F1_0 =  0.9677004431790632    F1_1 =  0.603224792571476
ModelsExpScriber/20200512_083058/cp-005.ckpt
657/657 [==============================] - 39s 60ms/step - loss: 0.2628 - Rec_0: 0.9831 - Prec_0: 0.9553 - Rec_1: 0.4158 - Prec_1: 0.6594
F1_0 =  0.9690283454215081    F1_1 =  0.5100080147936082
ModelsExpScriber/20200512_083058/cp-006.ckpt
657/657 [==============================] - 39s 60ms/step - loss: 0.2812 - Rec_0: 0.9776 - Prec_0: 0.9594 - Rec_1: 0.4745 - Prec_1: 0.6246
F1_0 =  0.9684146275116742    F1_1 =  0.539317542498768
ModelsExpScriber/20200512_083058/cp-007.ckpt
657/657 [==============================] - 39s 59ms/step - loss: 0.3211 - Rec_0: 0.9830 - Prec_0: 0.9523 - Rec_1: 0.3734 - Prec_1: 0.6334
F1_0 =  0.9673850012005574    F1_1 =  0.4698151840339162
ModelsExpScriber/20200512_083058/cp-008.ckpt
657/657 [==============================] - 39s 59ms/step - loss: 0.2891 - Rec_0: 0.9725 - Prec_0: 0.9600 - Rec_1: 0.4843 - Prec_1: 0.5810
F1_0 =  0.9662067798149201    F1_1 =  0.5283018456241605
ModelsExpScriber/20200512_083058/cp-009.ckpt
657/657 [==============================] - 39s 59ms/step - loss: 0.3666 - Rec_0: 0.9800 - Prec_0: 0.9562 - Rec_1: 0.4289 - Prec_1: 0.6281
F1_0 =  0.9679513488306916    F1_1 =  0.5096975009496517
ModelsExpScriber/20200512_083058/cp-010.ckpt
657/657 [==============================] - 39s 59ms/step - loss: 0.3305 - Rec_0: 0.9846 - Prec_0: 0.9530 - Rec_1: 0.3825 - Prec_1: 0.6614
F1_0 =  0.9685353174781889    F1_1 =  0.4846980998682299

----------------------------------------------------------------------------------------------
==============================================================================================






==============================================================================================
----------------------------------------------------------------------------------------------

20200514_213049

vocab_size = 32005
segment_size = 48
batch_size = 32
train_layer_ind = 0
learat = 1e-5
num_epochs = 10

TRAINING
Epoch 001: (Training)   Loss: 0.132, Accuracy: 95.338%
Epoch 002: (Training)   Loss: 0.094, Accuracy: 96.041%
Epoch 003: (Training)   Loss: 0.074, Accuracy: 97.216%
Epoch 004: (Training)   Loss: 0.049, Accuracy: 98.617%
Epoch 005: (Training)   Loss: 0.030, Accuracy: 99.496%
Epoch 006: (Training)   Loss: 0.020, Accuracy: 99.836%
Epoch 007: (Training)   Loss: 0.015, Accuracy: 99.929%
Epoch 008: (Training)   Loss: 0.013, Accuracy: 99.960%
Epoch 009: (Training)   Loss: 0.012, Accuracy: 99.973%
Epoch 010: (Training)   Loss: 0.010, Accuracy: 99.981%

EVALUATION
ModelsExpScriber/20200514_213049/cp-001.ckpt
657/657 [==============================] - 58s 89ms/step - loss: 0.1197 - Rec_0: 0.9588 - Prec_0: 0.9803 - Rec_1: 0.7546 - Prec_1: 0.5904
F1_0 =  0.9694248909920045,   F1_1 =  0.6624641499339768
ModelsExpScriber/20200514_213049/cp-002.ckpt
657/657 [==============================] - 57s 87ms/step - loss: 0.1190 - Rec_0: 0.9827 - Prec_0: 0.9626 - Rec_1: 0.5150 - Prec_1: 0.7013
F1_0 =  0.9725870651278188,   F1_1 =  0.5939028679800847
ModelsExpScriber/20200514_213049/cp-003.ckpt
657/657 [==============================] - 58s 88ms/step - loss: 0.1388 - Rec_0: 0.9785 - Prec_0: 0.9622 - Rec_1: 0.5111 - Prec_1: 0.6520
F1_0 =  0.9702940198727419,   F1_1 =  0.572996714566175
ModelsExpScriber/20200514_213049/cp-004.ckpt
657/657 [==============================] - 57s 87ms/step - loss: 0.1874 - Rec_0: 0.9794 - Prec_0: 0.9612 - Rec_1: 0.4974 - Prec_1: 0.6546
F1_0 =  0.9701947846355773,   F1_1 =  0.5652819411764158
ModelsExpScriber/20200514_213049/cp-005.ckpt
657/657 [==============================] - 58s 88ms/step - loss: 0.2478 - Rec_0: 0.9746 - Prec_0: 0.9636 - Rec_1: 0.5320 - Prec_1: 0.6226
F1_0 =  0.9690889593067088,   F1_1 =  0.5737416036529801
ModelsExpScriber/20200514_213049/cp-006.ckpt
657/657 [==============================] - 58s 88ms/step - loss: 0.2628 - Rec_0: 0.9804 - Prec_0: 0.9543 - Rec_1: 0.4027 - Prec_1: 0.6176
F1_0 =  0.9671537627708837,   F1_1 =  0.4875543160595617
ModelsExpScriber/20200514_213049/cp-007.ckpt
657/657 [==============================] - 57s 87ms/step - loss: 0.2987 - Rec_0: 0.9826 - Prec_0: 0.9550 - Rec_1: 0.4119 - Prec_1: 0.6505
F1_0 =  0.968620232262256,    F1_1 =  0.5043964790017256
ModelsExpScriber/20200514_213049/cp-008.ckpt
657/657 [==============================] - 57s 87ms/step - loss: 0.2908 - Rec_0: 0.9776 - Prec_0: 0.9610 - Rec_1: 0.4961 - Prec_1: 0.6355
F1_0 =  0.9692542596874862,   F1_1 =  0.5571847630911239
ModelsExpScriber/20200514_213049/cp-009.ckpt
657/657 [==============================] - 57s 87ms/step - loss: 0.3293 - Rec_0: 0.9783 - Prec_0: 0.9578 - Rec_1: 0.4517 - Prec_1: 0.6212
F1_0 =  0.9679468037067517,   F1_1 =  0.5230536999664555
ModelsExpScriber/20200514_213049/cp-010.ckpt
657/657 [==============================] - 57s 87ms/step - loss: 0.3017 - Rec_0: 0.9727 - Prec_0: 0.9640 - Rec_1: 0.5379 - Prec_1: 0.6081
F1_0 =  0.9683371030042839,   F1_1 =  0.570834779269068

----------------------------------------------------------------------------------------------
==============================================================================================






!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

20200526_092714

vocab_size = 32005
segment_size = 80
batch_size = 32
train_layer_ind = 0
learat = 1e-5
num_epochs = 10







==============================================================================================
----------------------------------------------------------------------------------------------

20200518_092049


vocab_size = 32005
segment_size = 64
batch_size = 32
train_layer_ind = 0
learat = 1e-5
num_epochs = 10


TRAINING
Epoch 001: (Training)   Loss: 0.137, Accuracy: 95.340%
Epoch 002: (Training)   Loss: 0.095, Accuracy: 96.062%
Epoch 003: (Training)   Loss: 0.074, Accuracy: 97.277%
Epoch 004: (Training)   Loss: 0.049, Accuracy: 98.648%
Epoch 005: (Training)   Loss: 0.030, Accuracy: 99.523%
Epoch 006: (Training)   Loss: 0.021, Accuracy: 99.840%
Epoch 007: (Training)   Loss: 0.016, Accuracy: 99.931%
Epoch 008: (Training)   Loss: 0.014, Accuracy: 99.963%
Epoch 009: (Training)   Loss: 0.012, Accuracy: 99.972%
Epoch 010: (Training)   Loss: 0.011, Accuracy: 99.979%

EVALUATING
ModelsExpScriber/20200518_092049/cp-001.ckpt
657/657 [==============================] - 89s 135ms/step - loss: 0.1132 - Rec_0: 0.9835 - Prec_0: 0.9615 - Rec_1: 0.4993 - Prec_1: 0.7038
F1_0 =  0.9723597765815107    F1_1 =  0.5841924701664425
ModelsExpScriber/20200518_092049/cp-002.ckpt
657/657 [==============================] - 88s 134ms/step - loss: 0.1174 - Rec_0: 0.9788 - Prec_0: 0.9661 - Rec_1: 0.5640 - Prec_1: 0.6771
F1_0 =  0.9724560242219199    F1_1 =  0.6153846153846154
ModelsExpScriber/20200518_092049/cp-003.ckpt
657/657 [==============================] - 85s 129ms/step - loss: 0.1279 - Rec_0: 0.9842 - Prec_0: 0.9579 - Rec_1: 0.4497 - Prec_1: 0.6918
F1_0 =  0.9708786891536968    F1_1 =  0.5450949732268716
ModelsExpScriber/20200518_092049/cp-004.ckpt
657/657 [==============================] - 70s 106ms/step - loss: 0.1817 - Rec_0: 0.9842 - Prec_0: 0.9518 - Rec_1: 0.3668 - Prec_1: 0.6467
F1_0 =  0.9677662805198752    F1_1 =  0.4681382805680207
ModelsExpScriber/20200518_092049/cp-005.ckpt
657/657 [==============================] - 71s 109ms/step - loss: 0.2558 - Rec_0: 0.9870 - Prec_0: 0.9495 - Rec_1: 0.3329 - Prec_1: 0.6684
F1_0 =  0.9679027154595492    F1_1 =  0.4444444312163281
ModelsExpScriber/20200518_092049/cp-006.ckpt
657/657 [==============================] - 71s 108ms/step - loss: 0.2809 - Rec_0: 0.9789 - Prec_0: 0.9567 - Rec_1: 0.4367 - Prec_1: 0.6200
F1_0 =  0.9676961053844115    F1_1 =  0.5124473391135462
ModelsExpScriber/20200518_092049/cp-007.ckpt
657/657 [==============================] - 72s 109ms/step - loss: 0.2597 - Rec_0: 0.9866 - Prec_0: 0.9513 - Rec_1: 0.3577 - Prec_1: 0.6774
F1_0 =  0.9686216410603923    F1_1 =  0.46817596916973325
ModelsExpScriber/20200518_092049/cp-008.ckpt
657/657 [==============================] - 72s 109ms/step - loss: 0.2695 - Rec_0: 0.9690 - Prec_0: 0.9646 - Rec_1: 0.5483 - Prec_1: 0.5821
F1_0 =  0.9668314014133931    F1_1 =  0.5647058637431612
ModelsExpScriber/20200518_092049/cp-009.ckpt
657/657 [==============================] - 72s 110ms/step - loss: 0.2483 - Rec_0: 0.9743 - Prec_0: 0.9617 - Rec_1: 0.5072 - Prec_1: 0.6085
F1_0 =  0.9679920408341952    F1_1 =  0.5532217481033047
ModelsExpScriber/20200518_092049/cp-010.ckpt
657/657 [==============================] - 72s 109ms/step - loss: 0.3648 - Rec_0: 0.9810 - Prec_0: 0.9571 - Rec_1: 0.4413 - Prec_1: 0.6457
F1_0 =  0.9688886745632673    F1_1 =  0.5242342290072619

----------------------------------------------------------------------------------------------
==============================================================================================






==============================================================================================
----------------------------------------------------------------------------------------------

20200521_222525

vocab_size = 32005
segment_size = 32
batch_size = 64
train_layer_ind = 0
learat = 1e-5
num_epochs = 10
regularisation = True
hidden_dropout_prob = 0.4

TRAINING
Epoch 001: (Training)   Loss: 0.197, Accuracy: 93.976%
Epoch 002: (Training)   Loss: 0.133, Accuracy: 94.569%
Epoch 003: (Training)   Loss: 0.121, Accuracy: 94.831%
Epoch 004: (Training)   Loss: 0.115, Accuracy: 95.012%
Epoch 005: (Training)   Loss: 0.110, Accuracy: 95.112%
Epoch 006: (Training)   Loss: 0.107, Accuracy: 95.232%
Epoch 007: (Training)   Loss: 0.105, Accuracy: 95.320%
Epoch 008: (Training)   Loss: 0.102, Accuracy: 95.396%
Epoch 009: (Training)   Loss: 0.100, Accuracy: 95.459%
Epoch 010: (Training)   Loss: 0.099, Accuracy: 95.538%

EVALUATION
ModelsExpScriber/20200521_222525/cp-001.ckpt
657/657 [==============================] - 42s 63ms/step - loss: 0.1358 - Rec_0: 0.9813 - Prec_0: 0.9588 - Rec_1: 0.4641 - Prec_1: 0.6614
F1_0 =  0.9699322597038849    F1_1 =  0.5454545454545454
ModelsExpScriber/20200521_222525/cp-002.ckpt
657/657 [==============================] - 39s 60ms/step - loss: 0.1272 - Rec_0: 0.9673 - Prec_0: 0.9724 - Rec_1: 0.6514 - Prec_1: 0.6108
F1_0 =  0.9698856828137792    F1_1 =  0.6304485264249382
ModelsExpScriber/20200521_222525/cp-003.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.1221 - Rec_0: 0.9761 - Prec_0: 0.9663 - Rec_1: 0.5679 - Prec_1: 0.6512
F1_0 =  0.9711877237562856    F1_1 =  0.6066945604648827
ModelsExpScriber/20200521_222525/cp-004.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.1235 - Rec_0: 0.9784 - Prec_0: 0.9643 - Rec_1: 0.5392 - Prec_1: 0.6624
F1_0 =  0.9712785365431594    F1_1 =  0.5944584025506361
ModelsExpScriber/20200521_222525/cp-005.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.1234 - Rec_0: 0.9706 - Prec_0: 0.9706 - Rec_1: 0.6260 - Prec_1: 0.6264
F1_0 =  0.9706071295992376    F1_1 =  0.6261835098484467
ModelsExpScriber/20200521_222525/cp-006.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.1274 - Rec_0: 0.9789 - Prec_0: 0.9642 - Rec_1: 0.5385 - Prec_1: 0.6675
F1_0 =  0.9715159144700759    F1_1 =  0.5960982670387037
ModelsExpScriber/20200521_222525/cp-007.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.1219 - Rec_0: 0.9748 - Prec_0: 0.9683 - Rec_1: 0.5940 - Prec_1: 0.6495
F1_0 =  0.9715235498394934    F1_1 =  0.6205250772828013
ModelsExpScriber/20200521_222525/cp-008.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.1229 - Rec_0: 0.9711 - Prec_0: 0.9713 - Rec_1: 0.6351 - Prec_1: 0.6339
F1_0 =  0.9712202470889949    F1_1 =  0.634496279505387
ModelsExpScriber/20200521_222525/cp-009.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.1314 - Rec_0: 0.9792 - Prec_0: 0.9632 - Rec_1: 0.5242 - Prec_1: 0.6642
F1_0 =  0.9711026500688833    F1_1 =  0.5859175676639523
ModelsExpScriber/20200521_222525/cp-010.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.1350 - Rec_0: 0.9691 - Prec_0: 0.9720 - Rec_1: 0.6449 - Prec_1: 0.6214
F1_0 =  0.9705368354195452    F1_1 =  0.6329275881319057

----------------------------------------------------------------------------------------------
==============================================================================================






==============================================================================================
----------------------------------------------------------------------------------------------

20200514_215321

vocab_size = 32005
segment_size = 32
batch_size = 64
train_layer_ind = 0  
learat = 1e-5
num_epochs = 10
regularisation = True
hidden_dropout_prob = 0.3

TRAINING
Epoch 001: (Training)   Loss: 0.174, Accuracy: 94.180%
Epoch 002: (Training)   Loss: 0.125, Accuracy: 94.740%
Epoch 003: (Training)   Loss: 0.112, Accuracy: 95.035%
Epoch 004: (Training)   Loss: 0.111, Accuracy: 95.148%
Epoch 005: (Training)   Loss: 0.103, Accuracy: 95.347%
Epoch 006: (Training)   Loss: 0.104, Accuracy: 95.348%
Epoch 007: (Training)   Loss: 0.100, Accuracy: 95.507%
Epoch 008: (Training)   Loss: 0.096, Accuracy: 95.634%
Epoch 009: (Training)   Loss: 0.094, Accuracy: 95.738%
Epoch 010: (Training)   Loss: 0.091, Accuracy: 95.860%

EVALUATION
ModelsExpScriber/20200514_215321/cp-001.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.1275 - Rec_0: 0.9724 - Prec_0: 0.9700 - Rec_1: 0.6175 - Prec_1: 0.6379
F1_0 =  0.9712073285548994    F1_1 =  0.6275289688359251
ModelsExpScriber/20200514_215321/cp-002.ckpt
657/657 [==============================] - 39s 59ms/step - loss: 0.1189 - Rec_0: 0.9741 - Prec_0: 0.9695 - Rec_1: 0.6103 - Prec_1: 0.6493
F1_0 =  0.9717768881011244    F1_1 =  0.6292059423179917
ModelsExpScriber/20200514_215321/cp-003.ckpt
657/657 [==============================] - 39s 60ms/step - loss: 0.2045 - Rec_0: 0.9991 - Prec_0: 0.9292 - Rec_1: 0.0326 - Prec_1: 0.7463   
F1_0 =  0.9629134871612458    F1_1 =  0.06253908441383978
ModelsExpScriber/20200514_215321/cp-004.ckpt
657/657 [==============================] - 39s 60ms/step - loss: 0.1218 - Rec_0: 0.9730 - Prec_0: 0.9705 - Rec_1: 0.6234 - Prec_1: 0.6453
F1_0 =  0.9717479099571166    F1_1 =  0.6341301677956721
ModelsExpScriber/20200514_215321/cp-005.ckpt
657/657 [==============================] - 39s 60ms/step - loss: 0.1274 - Rec_0: 0.9823 - Prec_0: 0.9588 - Rec_1: 0.4634 - Prec_1: 0.6730
F1_0 =  0.9704040272528628    F1_1 =  0.5488983366874417
ModelsExpScriber/20200514_215321/cp-007.ckpt
657/657 [==============================] - 40s 61ms/step - loss: 0.1278 - Rec_0: 0.9780 - Prec_0: 0.9662 - Rec_1: 0.5646 - Prec_1: 0.6685
F1_0 =  0.9720350753870156    F1_1 =  0.6121726687921667
ModelsExpScriber/20200514_215321/cp-008.ckpt
657/657 [==============================] - 39s 59ms/step - loss: 0.1371 - Rec_0: 0.9755 - Prec_0: 0.9669 - Rec_1: 0.5751 - Prec_1: 0.6483
F1_0 =  0.9711452442923013    F1_1 =  0.6094776929368941
ModelsExpScriber/20200514_215321/cp-009.ckpt
657/657 [==============================] - 39s 60ms/step - loss: 0.1342 - Rec_0: 0.9814 - Prec_0: 0.9616 - Rec_1: 0.5020 - Prec_1: 0.6793
F1_0 =  0.9713879533604448    F1_1 =  0.577327357025969
ModelsExpScriber/20200514_215321/cp-010.ckpt
657/657 [==============================] - 39s 60ms/step - loss: 0.1336 - Rec_0: 0.9752 - Prec_0: 0.9670 - Rec_1: 0.5770 - Prec_1: 0.6467
F1_0 =  0.9710882594861288    F1_1 =  0.6098654878891561

----------------------------------------------------------------------------------------------
==============================================================================================






==============================================================================================
----------------------------------------------------------------------------------------------

20200516_215600

vocab_size = 32005
segment_size = 32
batch_size = 64
train_layer_ind = 0  
learat = 1e-5
num_epochs = 10
regularisation = True
hidden_dropout_prob = 0.15

TRAINING
Epoch 001: (Training)   Loss: 0.143, Accuracy: 94.619%
Epoch 002: (Training)   Loss: 0.110, Accuracy: 95.134%
Epoch 003: (Training)   Loss: 0.101, Accuracy: 95.426%
Epoch 004: (Training)   Loss: 0.095, Accuracy: 95.695%
Epoch 005: (Training)   Loss: 0.088, Accuracy: 95.983%
Epoch 006: (Training)   Loss: 0.083, Accuracy: 96.254%
Epoch 007: (Training)   Loss: 0.077, Accuracy: 96.539%
Epoch 008: (Training)   Loss: 0.072, Accuracy: 96.825%
Epoch 009: (Training)   Loss: 0.066, Accuracy: 97.073%
Epoch 010: (Training)   Loss: 0.061, Accuracy: 97.337%

EVALUATION
ModelsExpScriber/20200516_215600/cp-001.ckpt
657/657 [==============================] - 53s 81ms/step - loss: 0.1262 - Rec_0: 0.9904 - Prec_0: 0.9509 - Rec_1: 0.3499 - Prec_1: 0.7414
F1_0 =  0.9702487237496235    F1_1 =  0.4753880276491071
ModelsExpScriber/20200516_215600/cp-002.ckpt
657/657 [==============================] - 53s 81ms/step - loss: 0.1137 - Rec_0: 0.9739 - Prec_0: 0.9696 - Rec_1: 0.6116 - Prec_1: 0.6484
F1_0 =  0.971747623380075    F1_1 =  0.6294927874345185
ModelsExpScriber/20200516_215600/cp-003.ckpt
657/657 [==============================] - 54s 82ms/step - loss: 0.1277 - Rec_0: 0.9848 - Prec_0: 0.9583 - Rec_1: 0.4550 - Prec_1: 0.7019
F1_0 =  0.9713620166546972    F1_1 =  0.5520792587899879
ModelsExpScriber/20200516_215600/cp-004.ckpt
657/657 [==============================] - 53s 80ms/step - loss: 0.1198 - Rec_0: 0.9824 - Prec_0: 0.9624 - Rec_1: 0.5124 - Prec_1: 0.6959
F1_0 =  0.9723055199800813    F1_1 =  0.590225565764224
ModelsExpScriber/20200516_215600/cp-005.ckpt
657/657 [==============================] - 54s 81ms/step - loss: 0.1315 - Rec_0: 0.9823 - Prec_0: 0.9616 - Rec_1: 0.5007 - Prec_1: 0.6897
F1_0 =  0.9718087744085006    F1_1 =  0.5801815516762941
ModelsExpScriber/20200516_215600/cp-006.ckpt
657/657 [==============================] - 55s 83ms/step - loss: 0.1340 - Rec_0: 0.9735 - Prec_0: 0.9674 - Rec_1: 0.5829 - Prec_1: 0.6333
F1_0 =  0.9704166463977012    F1_1 =  0.6070699897770054
ModelsExpScriber/20200516_215600/cp-007.ckpt
657/657 [==============================] - 53s 81ms/step - loss: 0.1539 - Rec_0: 0.9814 - Prec_0: 0.9612 - Rec_1: 0.4967 - Prec_1: 0.6770
F1_0 =  0.9711904864766149    F1_1 =  0.573042112235515
ModelsExpScriber/20200516_215600/cp-008.ckpt
657/657 [==============================] - 52s 79ms/step - loss: 0.1618 - Rec_0: 0.9782 - Prec_0: 0.9615 - Rec_1: 0.5020 - Prec_1: 0.6446
F1_0 =  0.9697910562602767    F1_1 =  0.5644036950405247
ModelsExpScriber/20200516_215600/cp-009.ckpt
657/657 [==============================] - 55s 83ms/step - loss: 0.1986 - Rec_0: 0.9859 - Prec_0: 0.9525 - Rec_1: 0.3747 - Prec_1: 0.6769
F1_0 =  0.9689187360859993    F1_1 =  0.48235293717538164
ModelsExpScriber/20200516_215600/cp-010.ckpt
657/657 [==============================] - 54s 82ms/step - loss: 0.2034 - Rec_0: 0.9825 - Prec_0: 0.9572 - Rec_1: 0.4419 - Prec_1: 0.6657
F1_0 =  0.9697230657968547    F1_1 =  0.531188715089968

----------------------------------------------------------------------------------------------
==============================================================================================






==============================================================================================
----------------------------------------------------------------------------------------------

20200518_230403

vocab_size = 32005
segment_size = 48
batch_size = 48
train_layer_ind = 0
learat = 1e-5
num_epochs = 10
regularisation = True
hidden_dropout_prob = 0.3

TRAINING
Epoch 001: (Training)   Loss: 0.179, Accuracy: 94.076%
Epoch 002: (Training)   Loss: 0.124, Accuracy: 94.763%
Epoch 003: (Training)   Loss: 0.111, Accuracy: 95.074%
Epoch 004: (Training)   Loss: 0.106, Accuracy: 95.256%
Epoch 005: (Training)   Loss: 0.102, Accuracy: 95.426%
Epoch 006: (Training)   Loss: 0.098, Accuracy: 95.553%
Epoch 007: (Training)   Loss: 0.095, Accuracy: 95.671%
Epoch 008: (Training)   Loss: 0.092, Accuracy: 95.796%
Epoch 009: (Training)   Loss: 0.089, Accuracy: 95.941%
Epoch 010: (Training)   Loss: 0.088, Accuracy: 96.019%

EVALUATING
ModelsExpScriber/20200518_230403/cp-001.ckpt
657/657 [==============================] - 76s 115ms/step - loss: 0.1299 - Rec_0: 0.9572 - Prec_0: 0.9787 - Rec_1: 0.7356 - Prec_1: 0.5750
F1_0 =  0.9678658343071576    F1_1 =  0.6454754138500162
ModelsExpScriber/20200518_230403/cp-002.ckpt
657/657 [==============================] - 74s 113ms/step - loss: 0.1204 - Rec_0: 0.9791 - Prec_0: 0.9645 - Rec_1: 0.5424 - Prec_1: 0.6712
F1_0 =  0.9717692626905777    F1_1 =  0.6
ModelsExpScriber/20200518_230403/cp-003.ckpt
657/657 [==============================] - 74s 113ms/step - loss: 0.1232 - Rec_0: 0.9750 - Prec_0: 0.9670 - Rec_1: 0.5764 - Prec_1: 0.6445
F1_0 =  0.970958218331034     F1_1 =  0.6085458648143556
ModelsExpScriber/20200518_230403/cp-004.ckpt
657/657 [==============================] - 74s 113ms/step - loss: 0.1317 - Rec_0: 0.9757 - Prec_0: 0.9645 - Rec_1: 0.5431 - Prec_1: 0.6375
F1_0 =  0.9700619692708409    F1_1 =  0.5865350906598578
ModelsExpScriber/20200518_230403/cp-005.ckpt
657/657 [==============================] - 75s 113ms/step - loss: 0.1269 - Rec_0: 0.9709 - Prec_0: 0.9709 - Rec_1: 0.6299 - Prec_1: 0.6299
F1_0 =  0.9708887266780077    F1_1 =  0.6298955591341094
ModelsExpScriber/20200518_230403/cp-006.ckpt
657/657 [==============================] - 74s 113ms/step - loss: 0.1306 - Rec_0: 0.9804 - Prec_0: 0.9635 - Rec_1: 0.5281 - Prec_1: 0.6793
F1_0 =  0.9718794004265007    F1_1 =  0.5941976103422162
ModelsExpScriber/20200518_230403/cp-007.ckpt
657/657 [==============================] - 74s 113ms/step - loss: 0.1388 - Rec_0: 0.9839 - Prec_0: 0.9587 - Rec_1: 0.4615 - Prec_1: 0.6931
F1_0 =  0.9711650970153265    F1_1 =  0.5540752346242399
ModelsExpScriber/20200518_230403/cp-008.ckpt
657/657 [==============================] - 74s 113ms/step - loss: 0.1386 - Rec_0: 0.9750 - Prec_0: 0.9675 - Rec_1: 0.5836 - Prec_1: 0.6474
F1_0 =  0.9712313130569261    F1_1 =  0.6138002193382586
ModelsExpScriber/20200518_230403/cp-009.ckpt
657/657 [==============================] - 74s 113ms/step - loss: 0.1496 - Rec_0: 0.9848 - Prec_0: 0.9592 - Rec_1: 0.4674 - Prec_1: 0.7068
F1_0 =  0.9718035397856721    F1_1 =  0.5626718836170242
ModelsExpScriber/20200518_230403/cp-010.ckpt
657/657 [==============================] - 74s 113ms/step - loss: 0.1805 - Rec_0: 0.9886 - Prec_0: 0.9529 - Rec_1: 0.3792 - Prec_1: 0.7235
F1_0 =  0.970440768254518     F1_1 =  0.49764452422145794

----------------------------------------------------------------------------------------------
==============================================================================================






!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!

Model trained with different strategy
Only top first, all of it after

20200524_160623

vocab_size = 32005
segment_size = 32
batch_size = 64
learat = 1e-5
training = False
hidden_dropout_prob = 0.1
numEpoTop = 5
numEpoAll = 10



